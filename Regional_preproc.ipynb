{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2729fe-6cd1-4973-9fc4-753ae6c15eaf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7ff6ce7612a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cf, cfplot as cfp\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4 as nc\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "# Quick plot to show the results\n",
    "from cartopy import config\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import scipy.ndimage as ndimage0\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "# from mpl_toolkits.basemap import addcyclic\n",
    "from cartopy.util import add_cyclic_point\n",
    "import matplotlib.pylab as pl\n",
    "from scipy import stats\n",
    "import regionmask\n",
    "import glob\n",
    "import dask\n",
    "from general_functions import *\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4340fb-6ecc-4d09-acdf-2bb1daaaff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "seas='JJA'\n",
    "reg='IPCC'\n",
    "nyear=1\n",
    "rebasing=False\n",
    "\n",
    "if (seas == \"DJF\"):\n",
    "    sind=1\n",
    "else:\n",
    "    sind=0\n",
    "\n",
    "print(sind)\n",
    "def rebase(dataset):\n",
    "    # ds = xr.open_dataset('intermediate_files/stable/gmst/tas_gmst_bq777.nc') #,engine='zarr')\n",
    "    dates=dataset[0,].dropna(dim='year').year  \n",
    "    print(dates)\n",
    "    datasets = []\n",
    "    test=dataset\n",
    "    for i in np.arange(0,6):\n",
    "        tmp=test[i,:].dropna(dim='year')\n",
    "        tmp['year']=dates\n",
    "#         print(tmp.year)\n",
    "        datasets.append(tmp)\n",
    "    dsnew = xr.concat(datasets, dim='cases')\n",
    "    # print(dsnew)\n",
    "    return(dsnew)\n",
    "def preprocess(ds):\n",
    "    print(ds.encoding['source'])\n",
    "    return(ds)\n",
    "\n",
    "def seasaverage_3(var,seas):\n",
    "    season={'DJF':0,'JFM':1,'FMA':2,'MAM':3,'AMJ':4,'MJJ':5,'JJA':6,'JAS':7,'ASO':8,'SON':9,'OND':10,'NDJ':11,'ann':None}\n",
    "    seasindex=season[seas]\n",
    "    if (seas == 'ann'):\n",
    "        var_seas=var.groupby('time.year').mean('time')\n",
    "    else:\n",
    "        if (var.ndim == 4):\n",
    "            var_seas=var.rolling(min_periods=3, center=True, time=3).mean()[:,seasindex::12,:,:]\n",
    "            var_seas=var_seas.groupby('time.year').mean('time') #rename({\"time\":\"year\"})\n",
    "        elif (var.ndim == 3): \n",
    "            var_seas=var.rolling(min_periods=3, center=True, time=3).mean()[seasindex::12,:,:]\n",
    "            var_seas=var_seas.groupby('time.year').mean('time')\n",
    "        print(var_seas)\n",
    "    return(var_seas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1e057-e0bc-4203-a83f-35c2c607d67d",
   "metadata": {},
   "source": [
    "script is set up to work with any variable, although function uses variable names 'tas' and 'ts' internally - this does not affect which variables can be run through this function (e.g. precipitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1e3ad8-a4b3-4c10-a8de-113db9c610a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bq777.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bu607.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bw848.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bw987.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bz227.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_cd269.nc\n",
      "<xarray.DataArray 'year' (year: 500)>\n",
      "array([2014, 2015, 2016, ..., 2511, 2512, 2513])\n",
      "Coordinates:\n",
      "  * year     (year) int64 2014 2015 2016 2017 2018 ... 2509 2510 2511 2512 2513\n",
      "    height   float64 1.5\n"
     ]
    }
   ],
   "source": [
    "gwspath='/path/to/workspace/'\n",
    "scenario='ssp370'\n",
    "factor={'tas':1,'pr':86400,'txx':1} # scale factors to convert units to e.g. mm/day\n",
    "gmstssp370={}\n",
    "regtemp_ssp={}\n",
    "gmst2={}\n",
    "test={}\n",
    "hist={}\n",
    "base_region={}\n",
    "piCbase_region={}\n",
    "base_mask={}\n",
    "\n",
    "# array of GMSTs for stabilisation runs in alphabetical order of run_id to later reorder by temperature level\n",
    "\n",
    "zipgmststab=sorted(glob.glob(gwspath+'intermediate_files/stable/gmst/tas_gmst_*.nc'))\n",
    "zipgmst=xr.open_mfdataset(zipgmststab,combine='nested',concat_dim='cases',preprocess=preprocess)['tas']\n",
    "zipgmst=np.nanmean(rebase(zipgmst),axis=1)\n",
    "\n",
    "# reorder by temperature level\n",
    "\n",
    "def sortbygmst(input):\n",
    "    input = [x for _,x in sorted(zip(zipgmst,input))]\n",
    "    return(input)\n",
    "\n",
    "def calc_regions(var,lat1=None,lat2=None,lon1=None,lon2=None,units='None',mask='None'):\n",
    "\n",
    "    # generate arrays for historical runs of seasonal averages & apply land mask if required\n",
    "    \n",
    "    fileshist=sorted(glob.glob(gwspath+'intermediate_files/historical/'+var+'/'+var+'_r*.nc'))\n",
    "    if (mask=='None'):\n",
    "        hist=seasaverage_3(xr.open_mfdataset(fileshist,combine='nested',concat_dim='cases')[var],seas)*factor[var] # gmst timeseries for all hist runs --> baseperiod\n",
    "    else:\n",
    "        hist=mask_land(seasaverage_3(xr.open_mfdataset(fileshist,combine='nested',concat_dim='cases')[var],seas)*factor[var]).transpose('cases','year','lat','lon')\n",
    "\n",
    "    lat=hist['lat']\n",
    "    lon=hist['lon']\n",
    "\n",
    "    # climatology: first 50 years of hist (base)    \n",
    "    base=hist[:,0:50,:,:].mean('cases').mean('year')\n",
    "\n",
    "    # define regionmasks based on IPCC or lat lon slices for historical and climatology (base)\n",
    "    if (lat1==None):\n",
    "        base_mask=regionmask.defined_regions.ar6.land.mask_3D(base)\n",
    "        hist_mask=regionmask.defined_regions.ar6.land.mask_3D(hist)\n",
    "    else:\n",
    "        base=lonflip(mask_land(base)).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2))\n",
    "        base_mask=1.\n",
    "\n",
    "    # define weights for averaging based on cos(lat)  \n",
    "    if (lat1==None):\n",
    "        weights = np.cos(np.deg2rad(base.lat))\n",
    "    else:\n",
    "         weights = np.cos(np.deg2rad(base.lat)).sel(lat=slice(lat1,lat2))\n",
    "\n",
    "    # climatological values for each region (regional average of base)\n",
    "    base_region = base.weighted(base_mask*weights).mean(dim=(\"lat\", \"lon\")).values\n",
    " \n",
    "    if (units != '%'):\n",
    "        ts_hist_regional = hist.weighted(hist_mask * weights).mean(dim=(\"lat\", \"lon\"))-base_region\n",
    "        print('no units specified')\n",
    "    else:\n",
    "        ts_hist_regional = 100*(hist.weighted(hist_mask * weights).mean(dim=(\"lat\", \"lon\"))-base_region)/base_region\n",
    "        print('units %')\n",
    "\n",
    "    # tas = stabilisation input var\n",
    "    files=sortbygmst(sorted(glob.glob(gwspath+'/intermediate_files/stable/'+var+'/'+var+'_?????.nc')))\n",
    "    tasfiles=xr.open_mfdataset(files,combine='nested',concat_dim='cases',preprocess=preprocess)\n",
    "    if (mask=='None'):\n",
    "        tas=seasaverage_3(tasfiles[var],seas)*factor[var]\n",
    "    else:\n",
    "        tas=mask_land(seasaverage_3(tasfiles[var],seas)*factor[var]).transpose('cases','year','lat','lon')\n",
    "\n",
    "    if (rebasing==True):\n",
    "        tas=rebase(tas)\n",
    "\n",
    "    # tas_ssp370 = transient input var\n",
    "    transientfiles=sorted(glob.glob('/gws/nopw/j04/realproj/users/adittus/intermediate_files/'+scenario+'/'+var+'/'+var+'_r*.nc'))\n",
    "    transienttas=xr.open_mfdataset(transientfiles,combine='nested',concat_dim='cases')\n",
    "    if (mask=='None'):\n",
    "        tas_ssp370=seasaverage_3(transienttas[var],seas)*factor[var]\n",
    "    else:\n",
    "        tas_ssp370=mask_land(seasaverage_3(transienttas[var],seas)*factor[var]).transpose('cases','year','lat','lon')\n",
    "    if (lat1==None):\n",
    "        mask_full = regionmask.defined_regions.ar6.land.mask_3D(tas)\n",
    "    else:\n",
    "        tas=lonflip(mask_land(tas)).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2))\n",
    "        mask_full = 1.\n",
    "        \n",
    "    weights = np.cos(np.deg2rad(tas.lat))\n",
    "\n",
    "    # calc stabilisation regional timeseries\n",
    "    \n",
    "    if (units != '%'):\n",
    "        ts_airtemps_regional = tas.weighted(mask_full * weights).mean(dim=(\"lat\", \"lon\")) #-base_region\n",
    "        print('no units specified')\n",
    "    else:\n",
    "        ts_airtemps_regional = 100*(tas.weighted(mask_full * weights).mean(dim=(\"lat\", \"lon\"))-base_region)/base_region\n",
    "        print('units %')\n",
    "    \n",
    "    # calc scenario regional timeseries\n",
    "\n",
    "    if (lat1==None):\n",
    "        mask_transient = regionmask.defined_regions.ar6.land.mask_3D(tas_ssp370)\n",
    "    else:\n",
    "        tas_ssp370=lonflip(mask_land(tas_ssp370)).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2))\n",
    "        mask_transient = 1.\n",
    "    weights2 = np.cos(np.deg2rad(tas_ssp370.lat))\n",
    "    if (units != '%'):\n",
    "        transient_airtemps_regional = tas_ssp370.weighted(mask_transient * weights2).mean(dim=(\"lat\", \"lon\")) #-base_region\n",
    "        print('no units specified')\n",
    "    else:\n",
    "        print('units %')\n",
    "        transient_airtemps_regional = 100*(tas_ssp370.weighted(mask_transient * weights2).mean(dim=(\"lat\", \"lon\"))-base_region)/base_region\n",
    "# calculate stable gmst \n",
    "\n",
    "    gmststab=sortbygmst(sorted(glob.glob('/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_*.nc')))\n",
    "    gmst=xr.open_mfdataset(gmststab,combine='nested',concat_dim='cases',preprocess=preprocess)['tas']\n",
    "    if (rebasing == True):\n",
    "        gmst=rebase(gmst)\n",
    "    gmstbase=sorted(glob.glob('/gws/nopw/j04/realproj/users/adittus/intermediate_files/historical/gmst/tas_gmst_*.nc'))\n",
    "    gmstref=xr.open_mfdataset(gmstbase,combine='nested',concat_dim='cases')['tas']\n",
    "    base=gmstref[:,0:50].mean('cases').mean('year')\n",
    "    gmst2=gmst-base\n",
    "\n",
    "    # calculate transient_gmst \n",
    "\n",
    "    gmstssp=sorted(glob.glob('/gws/nopw/j04/realproj/users/adittus/intermediate_files/ssp370/gmst/tas_gmst_*.nc'))\n",
    "    gmstsspt=xr.open_mfdataset(gmstssp,combine='nested',concat_dim='cases')['tas']\n",
    "    gmstssp370=gmstsspt-base\n",
    "    return(gmstssp370,transient_airtemps_regional,gmst2,ts_airtemps_regional,base_region,piCbase_region,base_mask,ts_hist_regional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2934a99e-bee1-4dcc-b5c2-9c9f92152a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'pr' (cases: 16, year: 165, lat: 144, lon: 192)>\n",
      "dask.array<transpose, shape=(16, 165, 144, 192), dtype=float64, chunksize=(1, 1, 144, 192), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 -89.38 -88.12 -86.88 -85.62 ... 86.88 88.12 89.38\n",
      "  * lon      (lon) float64 0.9375 2.812 4.688 6.562 ... 353.4 355.3 357.2 359.1\n",
      "  * year     (year) int64 1850 1851 1852 1853 1854 ... 2010 2011 2012 2013 2014\n",
      "Dimensions without coordinates: cases\n",
      "units %\n",
      "/gws/nopw/j04/realproj/users/adittus//intermediate_files/stable/pr/pr_bq777.nc\n",
      "/gws/nopw/j04/realproj/users/adittus//intermediate_files/stable/pr/pr_bw848.nc\n",
      "/gws/nopw/j04/realproj/users/adittus//intermediate_files/stable/pr/pr_bz227.nc\n",
      "/gws/nopw/j04/realproj/users/adittus//intermediate_files/stable/pr/pr_cd269.nc\n",
      "/gws/nopw/j04/realproj/users/adittus//intermediate_files/stable/pr/pr_bw987.nc\n",
      "/gws/nopw/j04/realproj/users/adittus//intermediate_files/stable/pr/pr_bu607.nc\n",
      "<xarray.DataArray 'pr' (cases: 6, year: 526, lat: 144, lon: 192)>\n",
      "dask.array<transpose, shape=(6, 526, 144, 192), dtype=float64, chunksize=(1, 1, 144, 192), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 -89.38 -88.12 -86.88 -85.62 ... 86.88 88.12 89.38\n",
      "  * lon      (lon) float64 0.9375 2.812 4.688 6.562 ... 353.4 355.3 357.2 359.1\n",
      "  * year     (year) int64 2014 2015 2016 2017 2018 ... 2535 2536 2537 2538 2539\n",
      "Dimensions without coordinates: cases\n",
      "<xarray.DataArray 'pr' (cases: 16, year: 86, lat: 144, lon: 192)>\n",
      "dask.array<transpose, shape=(16, 86, 144, 192), dtype=float64, chunksize=(1, 1, 144, 192), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 -89.38 -88.12 -86.88 -85.62 ... 86.88 88.12 89.38\n",
      "  * lon      (lon) float64 0.9375 2.812 4.688 6.562 ... 353.4 355.3 357.2 359.1\n",
      "  * year     (year) int64 2015 2016 2017 2018 2019 ... 2096 2097 2098 2099 2100\n",
      "Dimensions without coordinates: cases\n",
      "units %\n",
      "units %\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bq777.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bw848.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bz227.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_cd269.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bw987.nc\n",
      "/gws/nopw/j04/realproj/users/adittus/intermediate_files/stable/gmst/tas_gmst_bu607.nc\n"
     ]
    }
   ],
   "source": [
    "region='IPCC'\n",
    "\n",
    "for var in ['pr']:\n",
    "    gmstssp370[var],regtemp_ssp[var],gmst2[var],test[var],base_region[var],piCbase_region[var],base_mask[var],hist[var]=calc_regions(var,units='%',mask='land')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ed4e8-26fd-42ef-9bf9-db3e0095e302",
   "metadata": {},
   "source": [
    "save timeseries to netcdf for next script: Figues3a4_r1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b5680b9-aed4-4237-8ac1-303ceffdd04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (region != 'IPCC'):\n",
    "    netcdf_dataset=xr.Dataset(\n",
    "         data_vars=dict(\n",
    "        pr_region_mean=([\"run\", \"year\"], test[var].values),\n",
    "             # year=test[var].year,\n",
    "             branch_year=[2014,2020,2025,2025,2030,2040],\n",
    "             branch_scenario=['historical','SSP3-7.0','SSP3-7.0','SSP2-4.5','SSP1-1.9','SSP3-7.0']\n",
    "         ),\n",
    "        coords=dict(\n",
    "            year=test[var].year,\n",
    "        ),\n",
    "        attrs=dict(region=reg,\n",
    "                  season=seas,\n",
    "                  branch_info=['hist 2014','2020 SSP370','2025 SSP370','2025 SSP245','2030 SSP119','2040 SSP370']),\n",
    "    )\n",
    "    netcdf_dataset.to_netcdf('timeseries/'+var+'_'+region+'_'+seas+'_stable.nc')\n",
    "    netcdf_dataset=xr.Dataset(\n",
    "         data_vars=dict(\n",
    "        pr_region_mean=([\"run\", \"year\"], regtemp_ssp[var].values),\n",
    "             # year=regtemp_ssp[var].year\n",
    "    \n",
    "         ),\n",
    "        coords=dict(\n",
    "            year=regtemp_ssp[var].year,\n",
    "        ),\n",
    "        attrs=dict(region=reg,\n",
    "                  season=seas),\n",
    "    )\n",
    "    netcdf_dataset.to_netcdf('timeseries/'+var+'_'+region+'_'+seas+'_transient.nc')\n",
    "\n",
    "else:\n",
    "    netcdf_dataset=xr.Dataset(\n",
    "         data_vars=dict(\n",
    "        pr_region_mean=([\"run\", \"year\",\"region\"], test[var].values),\n",
    "             names=base_mask[var].names.values,\n",
    "             # year=test[var].year,\n",
    "             branch_year=[2014,2020,2025,2025,2030,2040],\n",
    "             branch_scenario=['historical','SSP3-7.0','SSP3-7.0','SSP2-4.5','SSP1-1.9','SSP3-7.0']\n",
    "         ),\n",
    "        coords=dict(\n",
    "            year=test[var].year,\n",
    "        ),\n",
    "        attrs=dict(region=reg,\n",
    "                  season=seas,\n",
    "                  branch_info=['hist 2014','2020 SSP370','2025 SSP370','2025 SSP245','2030 SSP119','2040 SSP370']),\n",
    "    )\n",
    "    netcdf_dataset.to_netcdf('timeseries/'+var+'_'+region+'_'+seas+'_stable_land.nc')\n",
    "    \n",
    "    netcdf_dataset=xr.Dataset(\n",
    "         data_vars=dict(\n",
    "        pr_region_mean=([\"run\", \"year\",\"region\"], regtemp_ssp[var].values),\n",
    "             # year=regtemp_ssp[var].year\n",
    "    \n",
    "         ),\n",
    "        coords=dict(\n",
    "            year=regtemp_ssp[var].year,\n",
    "        ),\n",
    "        attrs=dict(region=reg,\n",
    "                  season=seas),\n",
    "    )\n",
    "    netcdf_dataset.to_netcdf('timeseries/'+var+'_'+region+'_'+seas+'_'+scenario+'_land.nc')\n",
    "    \n",
    "    netcdf_dataset=xr.Dataset(\n",
    "         data_vars=dict(\n",
    "        pr_region_mean=([\"run\", \"year\",\"region\"], hist[var].values),\n",
    "             # year=regtemp_ssp[var].year\n",
    "    \n",
    "         ),\n",
    "        coords=dict(\n",
    "            year=hist[var].year,\n",
    "        ),\n",
    "        attrs=dict(region=reg,\n",
    "                  season=seas),\n",
    "    )\n",
    "    netcdf_dataset.to_netcdf('timeseries/'+var+'_'+region+'_'+seas+'_hist_land.nc')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a03e1e-2763-44a0-8efe-046ae7ee4cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04374aa-7683-403b-965b-741f61b26d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbenv1",
   "language": "python",
   "name": "nbenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
